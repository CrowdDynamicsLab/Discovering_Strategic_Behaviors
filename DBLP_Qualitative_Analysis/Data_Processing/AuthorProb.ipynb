{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "from collections import defaultdict\n",
    "\n",
    "from Author import *\n",
    "from Venue import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = [2000, 2013, 201700, 201701, 201800, 201801, \n",
    "               201900, 201901, 201902, 201903, 201904, 201905, \n",
    "               201906, 201907, 201908, 201909, 201910, 201911, \n",
    "               201912, 201913, 201914]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Year 2000 ~ 2018 (inclusive)\n",
    "## PA * Latest * Field * Self = 2*2*2*2 = 16\n",
    "## S_{1,i} -> PA: Normal PA (p=0.1, p/#nodes + (1-p)indegree/sum_of_indegree), Uniform (1/#nodes)\n",
    "## S_{4,i} -> Latest: Normal Latest (beta(10,1), x=1-(outyear-inyear)/(outyear-oldest_year)), Uniform (1/(outyear-oldest_year))\n",
    "## S_{2,i} -> Field: Similar (1-(1-e^(-||x-y||_2))/(1-e^(-2)), x&y L2-normalized), Different ((1-e^(-||x-y||_2))/(1-e^(-2)), x&y L2-normalized)\n",
    "## S_{3,i} -> Self: Prefer (coauthors: 0.9/#coauthors, non-coauthors: 0.1/#non-coauthors), Not Prefer (coauthors: 0.1/#coauthors, non-coauthors: 0.9/#non-coauthors)\n",
    "\n",
    "## 1st: Normal_PA * Normal_Latest * Similar_Field * Prefer_Self\n",
    "## 2nd: Normal_PA * Normal_Latest * Similar_Field * NotPrefer_Self\n",
    "## 3rd: Normal_PA * Normal_Latest * Different_Field * Prefer_Self\n",
    "## 4th: Normal_PA * Normal_Latest * Different_Field * NotPrefer_Self\n",
    "## 5th: Normal_PA * Uniform_Latest * Similar_Field * Prefer_Self\n",
    "## 6th: Normal_PA * Uniform_Latest * Similar_Field * NotPrefer_Self\n",
    "## 7th: Normal_PA * Uniform_Latest * Different_Field * Prefer_Self\n",
    "## 8th: Normal_PA * Uniform_Latest * Different_Field * NotPrefer_Self\n",
    "## 9th: Uniform_PA * Normal_Latest * Similar_Field * Prefer_Self\n",
    "## 10th: Uniform_PA * Normal_Latest * Similar_Field * NotPrefer_Self\n",
    "## 11th: Uniform_PA * Normal_Latest * Different_Field * Prefer_Self\n",
    "## 12th: Uniform_PA * Normal_Latest * Different_Field * NotPrefer_Self\n",
    "## 13th: Uniform_PA * Uniform_Latest * Similar_Field * Prefer_Self\n",
    "## 14th: Uniform_PA * Uniform_Latest * Similar_Field * NotPrefer_Self\n",
    "## 15th: Uniform_PA * Uniform_Latest * Different_Field * Prefer_Self\n",
    "## 16th: Uniform_PA * Uniform_Latest * Different_Field * NotPrefer_Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Year 2000 ~ 2018 (inclusive)\n",
    "## PA * Field * Self = 2*2*2 = 8\n",
    "## S_{1,i} -> PA: Normal PA (p=0.1, p/#nodes + (1-p)indegree/sum_of_indegree), Uniform (1/#nodes)\n",
    "## S_{2,i} -> Field: Similar (1-(1-e^(-||x-y||_2))/(1-e^(-2)), x&y L2-normalized), Different ((1-e^(-||x-y||_2))/(1-e^(-2)), x&y L2-normalized)\n",
    "## S_{3,i} -> Self: Prefer (coauthors: 0.9/#coauthors, non-coauthors: 0.1/#non-coauthors), Not Prefer (coauthors: 0.1/#coauthors, non-coauthors: 0.9/#non-coauthors)\n",
    "\n",
    "## 1st: Normal_PA * Similar_Field * Prefer_Self\n",
    "## 2nd: Normal_PA * Similar_Field * NotPrefer_Self\n",
    "## 3rd: Normal_PA * Different_Field * Prefer_Self\n",
    "## 4th: Normal_PA * Different_Field * NotPrefer_Self\n",
    "## 5th: Uniform_PA * Similar_Field * Prefer_Self\n",
    "## 6th: Uniform_PA * Similar_Field * NotPrefer_Self\n",
    "## 7th: Uniform_PA * Different_Field * Prefer_Self\n",
    "## 8th: Uniform_PA * Different_Field * NotPrefer_Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_authors =  pickle.load(open('content/content_authors.pkl','rb'))\n",
    "\n",
    "author_fields, author_coauthors = defaultdict(dict), defaultdict(dict)\n",
    "author_sumdgs, author_eachdgs, author_cumcounts = defaultdict(np.int64), defaultdict(dict), defaultdict(np.int64)\n",
    "\n",
    "for group_name in group_names:\n",
    "    authors = pickle.load(open('author/authors_{}.pkl'.format(group_name),'rb'))    \n",
    "    for author in authors.values():\n",
    "        \n",
    "        for year, field in author.fields.items():\n",
    "            author_fields[author.id][year] = field/np.linalg.norm(field,2)\n",
    "        \n",
    "        for year, contents in author.contents.items():\n",
    "            year_coauthors = [content_authors[content] for content in contents]\n",
    "            year_coauthors = [coauthor for coauthors in year_coauthors for coauthor in coauthors]\n",
    "            author_coauthors[author.id][year] = set(year_coauthors)\n",
    "        \n",
    "        incitation_count = 0\n",
    "        for in_year in range(1980, 2019):\n",
    "            if in_year in author.incitations.keys():\n",
    "                incitation_count += len(author.incitations[in_year])\n",
    "            if in_year >= 1999:\n",
    "                author_sumdgs[in_year] += incitation_count\n",
    "                author_eachdgs[author.id][in_year] = incitation_count\n",
    "                \n",
    "        for year in range(min(author.contents.keys()), 2019):\n",
    "            author_cumcounts[year] += 1\n",
    "            \n",
    "    print(f\"Prepare info done for group {group_name}\")\n",
    "\n",
    "pickle.dump(author_fields, open('author/author_fields.pkl', 'wb'), -1)\n",
    "pickle.dump(author_coauthors, open('author/author_coauthors.pkl', 'wb'), -1)\n",
    "pickle.dump((author_sumdgs, author_eachdgs, author_cumcounts), open('author/author_prob_inputs.pkl', 'wb'), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues = pickle.load(open('venue/venues.pkl','rb'))\n",
    "venue_sumdgs, venue_eachdgs = defaultdict(np.int64), defaultdict(dict)\n",
    "\n",
    "for venue in venues.values():\n",
    "    incitation_count = 0\n",
    "    for in_year in range(1980, 2019):\n",
    "        if in_year in venue.contents.keys():\n",
    "            for count in venue.authors[in_year].values():\n",
    "                incitation_count += count\n",
    "        if in_year >= 1999:\n",
    "            venue_sumdgs[in_year] += incitation_count\n",
    "            venue_eachdgs[venue.id][in_year] = incitation_count             \n",
    "    \n",
    "pickle.dump((venue_sumdgs, venue_eachdgs), open('venue/venue_author_prob_inputs.pkl', 'wb'), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_fields = pickle.load(open('author/author_fields.pkl', 'rb'))\n",
    "author_coauthors = pickle.load(open('author/author_coauthors.pkl', 'rb'))\n",
    "author_sumdgs, author_eachdgs, author_cumcounts = pickle.load(open('author/author_prob_inputs.pkl', 'rb'))\n",
    "\n",
    "oldest = 1979\n",
    "superbeta = beta(a=10,b=1)\n",
    "superbeta_dist = np.array([superbeta.pdf((intime-oldest)/(outtime-oldest)) for outtime in range(2000,2019) for intime in range(1980,2018)]).reshape(2019-2000,2018-1980)\n",
    "\n",
    "def cal_cite_edgeprobs(outyear, author):\n",
    "    \n",
    "    outfield, outcitations = author_fields[author.id][outyear], author.outcitations[outyear]\n",
    "    coauthors = set()\n",
    "    for year in sorted(author_coauthors[author.id]):\n",
    "        if year>=outyear: break\n",
    "        for coauthor in author_coauthors[author.id][year]:\n",
    "            coauthors.add(coauthor)\n",
    "    \n",
    "    edgeprobs = []\n",
    "    for inyear, inauthor in outcitations:\n",
    "        \n",
    "        pnormal_pa = 0.1/author_cumcounts[outyear-1]+0.9*author_eachdgs[inauthor][outyear-1]/author_sumdgs[outyear-1]\n",
    "        puniform_pa = 1/author_cumcounts[outyear-1]\n",
    "        \n",
    "        pnormal_latest = superbeta_dist[outyear-2000, inyear-1980]\n",
    "        puniform_latest = 1/(outyear-oldest)\n",
    "        \n",
    "        psim_field = 1-(1-math.exp(-np.linalg.norm(outfield-author_fields[inauthor][inyear],2)))/(1-math.exp(-2))\n",
    "        pdif_field = 1-psim_field\n",
    "        \n",
    "        ppre_self = 0.9/len(coauthors) if inauthor in coauthors else 0.1/(author_cumcounts[outyear-1]-len(coauthors))\n",
    "        pnot_self = 0.1/len(coauthors) if inauthor in coauthors else 0.9/(author_cumcounts[outyear-1]-len(coauthors))\n",
    "        \n",
    "        temp1 = np.outer([pnormal_pa,puniform_pa],[pnormal_latest,puniform_latest]).flatten()\n",
    "        temp2 = np.outer([psim_field,pdif_field],[ppre_self,pnot_self]).flatten()\n",
    "        edgeprobs.append(np.outer(temp1,temp2).flatten())\n",
    "\n",
    "    return np.array(edgeprobs, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_fields = pickle.load(open('author/author_fields.pkl', 'rb'))\n",
    "venue_fields = pickle.load(open('venue/venue_fields.pkl', 'rb'))\n",
    "venue_cumcounts = pickle.load(open('venue/venue_cumcounts.pkl', 'rb'))\n",
    "venue_sumdgs, venue_eachdgs = pickle.load(open('venue/venue_author_prob_inputs.pkl', 'rb'))\n",
    "\n",
    "def cal_pub_edgeprobs(outyear, author):    \n",
    "    \n",
    "    outfield = author_fields[author.id][outyear]\n",
    "    covenues = set()\n",
    "    for year in sorted(author.venues.keys()):\n",
    "        if year>=outyear: break\n",
    "        for venue in author.venues[year]:\n",
    "            covenues.add(venue)\n",
    "    \n",
    "    edgeprobs = []\n",
    "    for invenue in author.venues[outyear]:\n",
    "    \n",
    "        pnormal_pa = 0.1/venue_cumcounts[outyear-1]+0.9*venue_eachdgs[invenue][outyear-1]/venue_sumdgs[outyear-1]\n",
    "        puniform_pa = 1/venue_cumcounts[outyear-1]\n",
    "        \n",
    "        psim_field = 1-(1-math.exp(-np.linalg.norm(outfield-venue_fields[invenue][outyear],2)))/(1-math.exp(-2))\n",
    "        pdif_field = 1-psim_field\n",
    "        \n",
    "        ppre_self = 0.9/len(covenues) if invenue in covenues else 0.1/(venue_cumcounts[outyear-1]-len(covenues))\n",
    "        pnot_self = 0.1/len(covenues) if invenue in covenues else 0.9/(venue_cumcounts[outyear-1]-len(covenues))\n",
    "        \n",
    "        temp1 = np.array([pnormal_pa,puniform_pa])\n",
    "        temp2 = np.outer([psim_field,pdif_field],[ppre_self,pnot_self]).flatten()\n",
    "        edgeprobs.append(np.outer(temp1,temp2).flatten())\n",
    "\n",
    "    return np.array(edgeprobs, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group_name in group_names[1:]:\n",
    "    print('Reading group {}'.format(group_name))\n",
    "    authors = pickle.load(open('author/authors_{}.pkl'.format(group_name),'rb'))\n",
    "    print('Edgeprob-calculation start for group {}, size {}'.format(group_name, len(authors)))\n",
    "    for i, author in enumerate(authors.values()):\n",
    "        for outyear in author.outcitations.keys():\n",
    "            if outyear >= 2000:\n",
    "                author.update_cite_edgellhs(outyear, cal_cite_edgeprobs(outyear, author))\n",
    "                author.update_pub_edgellhs(outyear, cal_pub_edgeprobs(outyear, author))\n",
    "        if (i+1)%10000==0: print('Finish', i+1)\n",
    "    print('Writing group {}'.format(group_name))\n",
    "    pickle.dump(authors, open('author/authors_{}.pkl'.format(group_name), 'wb'), -1)\n",
    "    del authors\n",
    "    print('Edgeprob-calculation done for group {}'.format(group_name))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
