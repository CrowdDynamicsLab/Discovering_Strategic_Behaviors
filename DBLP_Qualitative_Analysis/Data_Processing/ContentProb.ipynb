{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "from collections import defaultdict\n",
    "\n",
    "from Content import *\n",
    "from Venue import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation Edge Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Year 2000 ~ 2018 (inclusive)\n",
    "## PA * Latest * Field * Self = 2*2*2*2 = 16\n",
    "## PA: Normal PA (p=0.1, p/#nodes + (1-p)indegree/sum_of_indegree), Uniform (1/#nodes)\n",
    "## Latest: Normal Latest (beta(10,1), x=1-(outyear-inyear)/(outyear-oldest_year)), Uniform (1/(outyear-oldest_year))\n",
    "## Field: Similar (1-(1-e^(-||x-y||_2))/(1-e^(-2)), x&y L2-normalized), Different ((1-e^(-||x-y||_2))/(1-e^(-2)), x&y L2-normalized)\n",
    "## Self: Prefer (coauthors: 0.9/#coauthors, non-coauthors: 0.1/#non-coauthors), Not Prefer (coauthors: 0.1/#coauthors, non-coauthors: 0.9/#non-coauthors)\n",
    "\n",
    "## 1st: Normal_PA * Normal_Latest * Similar_Field * Prefer_Self\n",
    "## 2nd: Normal_PA * Normal_Latest * Similar_Field * NotPrefer_Self\n",
    "## 3rd: Normal_PA * Normal_Latest * Different_Field * Prefer_Self\n",
    "## 4th: Normal_PA * Normal_Latest * Different_Field * NotPrefer_Self\n",
    "## 5th: Normal_PA * Uniform_Latest * Similar_Field * Prefer_Self\n",
    "## 6th: Normal_PA * Uniform_Latest * Similar_Field * NotPrefer_Self\n",
    "## 7th: Normal_PA * Uniform_Latest * Different_Field * Prefer_Self\n",
    "## 8th: Normal_PA * Uniform_Latest * Different_Field * NotPrefer_Self\n",
    "## 9th: Uniform_PA * Normal_Latest * Similar_Field * Prefer_Self\n",
    "## 10th: Uniform_PA * Normal_Latest * Similar_Field * NotPrefer_Self\n",
    "## 11th: Uniform_PA * Normal_Latest * Different_Field * Prefer_Self\n",
    "## 12th: Uniform_PA * Normal_Latest * Different_Field * NotPrefer_Self\n",
    "## 13th: Uniform_PA * Uniform_Latest * Similar_Field * Prefer_Self\n",
    "## 14th: Uniform_PA * Uniform_Latest * Similar_Field * NotPrefer_Self\n",
    "## 15th: Uniform_PA * Uniform_Latest * Different_Field * Prefer_Self\n",
    "## 16th: Uniform_PA * Uniform_Latest * Different_Field * NotPrefer_Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_sumdgs, content_eachdgs, content_fields, content_cumcounts = defaultdict(np.int64), defaultdict(dict), {}, defaultdict(np.int64)\n",
    "\n",
    "for year in range(1980, 2019):\n",
    "    contents = pickle.load(open('content/contents_{}.pkl'.format(year),'rb'))\n",
    "    for content in contents.values():\n",
    "        content_fields[content.id] = content.field/np.linalg.norm(content.field,2)\n",
    "        incitation_count = 0\n",
    "        for in_year in range(1980, 2019):\n",
    "            if in_year in content.incitations.keys():\n",
    "                incitation_count += len(content.incitations[in_year])\n",
    "            if in_year >= 1999:\n",
    "                content_sumdgs[in_year] += incitation_count\n",
    "                content_eachdgs[content.id][in_year] = incitation_count\n",
    "                if in_year >= content.year:\n",
    "                    content_cumcounts[in_year] += 1                \n",
    "    print(f\"Prepare info done for year {year}\")\n",
    "    \n",
    "pickle.dump((content_sumdgs, content_eachdgs, content_fields, content_cumcounts), open('content/content_prob_inputs.pkl', 'wb'), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_year = pickle.load(open('content/content_year.pkl','rb'))\n",
    "content_authors =  pickle.load(open('content/content_authors.pkl','rb'))\n",
    "author_contents =  pickle.load(open('author/author_contents.pkl','rb'))\n",
    "content_sumdgs, content_eachdgs, content_fields, content_cumcounts = pickle.load(open('content/content_prob_inputs.pkl', 'rb'))\n",
    "\n",
    "oldest = 1979\n",
    "superbeta = beta(a=10,b=1)\n",
    "superbeta_dist = np.array([superbeta.pdf((intime-oldest)/(outtime-oldest)) for outtime in range(2000,2019) for intime in range(1980,2018)]).reshape(2019-2000,2018-1980)\n",
    "\n",
    "def cal_cite_edgeprobs(outcontent):\n",
    "    \n",
    "    outyear, outfield, outcitations = outcontent.year, content_fields[outcontent.id], outcontent.outcitations\n",
    "    outcocontents = set()\n",
    "    for author,_,_ in outcontent.authors:\n",
    "        for year in author_contents[author].keys():\n",
    "            if year < outyear:\n",
    "                for outcocontent in author_contents[author][year]:\n",
    "                    outcocontents.add(outcocontent)\n",
    "\n",
    "    edgeprobs = []\n",
    "    for incontent in outcitations:\n",
    "         \n",
    "        pnormal_pa = 0.1/content_cumcounts[outyear-1]+0.9*content_eachdgs[incontent][outyear-1]/content_sumdgs[outyear-1]\n",
    "        puniform_pa = 1/content_cumcounts[outyear-1]\n",
    "\n",
    "        pnormal_latest = superbeta_dist[outyear-2000, content_year[incontent]-1980]\n",
    "        puniform_latest = 1/(outyear-oldest)\n",
    "\n",
    "        psim_field = 1-(1-math.exp(-np.linalg.norm(outfield-content_fields[incontent],2)))/(1-math.exp(-2))\n",
    "        pdif_field = 1-psim_field\n",
    "        \n",
    "        ppre_self = 0.9/len(outcocontents) if incontent in outcocontents else 0.1/(content_cumcounts[outyear-1]-len(outcocontents))\n",
    "        pnot_self = 0.1/len(outcocontents) if incontent in outcocontents else 0.9/(content_cumcounts[outyear-1]-len(outcocontents))\n",
    "        \n",
    "        temp1 = np.outer([pnormal_pa,puniform_pa],[pnormal_latest,puniform_latest]).flatten()\n",
    "        temp2 = np.outer([psim_field,pdif_field],[ppre_self,pnot_self]).flatten()\n",
    "        edgeprobs.append(np.outer(temp1,temp2).flatten())\n",
    "    \n",
    "    return np.array(edgeprobs, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2000, 2019):\n",
    "    print('Reading year {}'.format(year))\n",
    "    contents =  pickle.load(open('content/contents_{}.pkl'.format(year),'rb'))\n",
    "    print('Edgeprob-calculation start for year {}'.format(year))\n",
    "    for content in contents.values():\n",
    "        if len(content.outcitations)>0:\n",
    "            content.update_cite_edgellhs(cal_cite_edgeprobs(content))\n",
    "    print('Writing year {}'.format(year))\n",
    "    pickle.dump(contents, open('content/contents_{}.pkl'.format(year), 'wb'), -1)\n",
    "    del contents\n",
    "    print('Edgeprob-calculation done for year {}'.format(year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Edge Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Year 2000 ~ 2018 (inclusive)\n",
    "## PA * Field * Self = 2*2*2 = 8\n",
    "## PA: Normal PA (p=0.1, p/#nodes + (1-p)indegree/sum_of_indegree), Uniform (1/#nodes)\n",
    "## Field: Similar (1-(1-e^(-||x-y||_2))/(1-e^(-2)), x&y L2-normalized), Different ((1-e^(-||x-y||_2))/(1-e^(-2)), x&y L2-normalized)\n",
    "## Self: Prefer (coauthors: 0.9/#coauthors, non-coauthors: 0.1/#non-coauthors), Not Prefer (coauthors: 0.1/#coauthors, non-coauthors: 0.9/#non-coauthors)\n",
    "\n",
    "## 1st: Normal_PA * Similar_Field * Prefer_Self\n",
    "## 2nd: Normal_PA * Similar_Field * NotPrefer_Self\n",
    "## 3rd: Normal_PA * Different_Field * Prefer_Self\n",
    "## 4th: Normal_PA * Different_Field * NotPrefer_Self\n",
    "## 5th: Uniform_PA * Similar_Field * Prefer_Self\n",
    "## 6th: Uniform_PA * Similar_Field * NotPrefer_Self\n",
    "## 7th: Uniform_PA * Different_Field * Prefer_Self\n",
    "## 8th: Uniform_PA * Different_Field * NotPrefer_Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues = pickle.load(open('venue/venues.pkl','rb'))\n",
    "venue_sumdgs, venue_eachdgs = defaultdict(np.int64), defaultdict(dict)\n",
    "\n",
    "for venue in venues.values():\n",
    "    incitation_count = 0\n",
    "    for in_year in range(1980, 2019):\n",
    "        if in_year in venue.contents.keys():\n",
    "            incitation_count += len(venue.contents[in_year])\n",
    "        if in_year >= 1999:\n",
    "            venue_sumdgs[in_year] += incitation_count\n",
    "            venue_eachdgs[venue.id][in_year] = incitation_count             \n",
    "    \n",
    "pickle.dump((venue_sumdgs, venue_eachdgs), open('venue/venue_content_prob_inputs.pkl', 'wb'), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_authors =  pickle.load(open('content/content_authors.pkl','rb'))\n",
    "author_venues =  pickle.load(open('author/author_venues.pkl','rb'))\n",
    "venue_fields = pickle.load(open('venue/venue_fields.pkl', 'rb'))\n",
    "venue_cumcounts = pickle.load(open('venue/venue_cumcounts.pkl', 'rb'))\n",
    "venue_sumdgs, venue_eachdgs = pickle.load(open('venue/venue_content_prob_inputs.pkl', 'rb'))\n",
    "\n",
    "def cal_pub_edgeprobs(outcontent):\n",
    "    \n",
    "    outyear, outfield, invenue = outcontent.year, content.field/np.linalg.norm(content.field,2), outcontent.venue\n",
    "    outcovenues = set()\n",
    "    for author,_,_ in outcontent.authors:\n",
    "        for year in author_venues[author].keys():\n",
    "            if year < outyear:\n",
    "                for outcovenue in author_venues[author][year]:\n",
    "                    outcovenues.add(outcovenue)    \n",
    "         \n",
    "    pnormal_pa = 0.1/venue_cumcounts[outyear-1]+0.9*venue_eachdgs[invenue][outyear-1]/venue_sumdgs[outyear-1]\n",
    "    puniform_pa = 1/venue_cumcounts[outyear-1]\n",
    "\n",
    "    psim_field = 1-(1-math.exp(-np.linalg.norm(outfield-venue_fields[invenue][outyear],2)))/(1-math.exp(-2))\n",
    "    pdif_field = 1-psim_field\n",
    "        \n",
    "    ppre_self = 0.9/len(outcovenues) if invenue in outcovenues else 0.1/(venue_cumcounts[outyear-1]-len(outcovenues))\n",
    "    pnot_self = 0.1/len(outcovenues) if invenue in outcovenues else 0.9/(venue_cumcounts[outyear-1]-len(outcovenues))\n",
    "        \n",
    "    temp1 = np.array([pnormal_pa,puniform_pa])\n",
    "    temp2 = np.outer([psim_field,pdif_field],[ppre_self,pnot_self]).flatten()\n",
    "    edgeprob = np.outer(temp1,temp2).flatten()\n",
    "\n",
    "    return np.array(edgeprob, dtype=np.float32).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2000, 2019):\n",
    "    print('Reading year {}'.format(year))\n",
    "    contents =  pickle.load(open('content/contents_{}.pkl'.format(year),'rb'))\n",
    "    print('Edgeprob-calculation start for year {}'.format(year))\n",
    "    for content in contents.values():\n",
    "        if len(content.outcitations)>0:\n",
    "            content.update_pub_edgellhs(cal_pub_edgeprobs(content))\n",
    "    print('Writing year {}'.format(year))\n",
    "    pickle.dump(contents, open('content/contents_{}.pkl'.format(year), 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    del contents\n",
    "    print('Edgeprob-calculation done for year {}'.format(year))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
