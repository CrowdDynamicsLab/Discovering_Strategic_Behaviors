{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import lil_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from Content import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(line, next_venue_id):\n",
    "    \n",
    "    data = {}\n",
    "    if 'id' in line and \\\n",
    "        'title' in line and \\\n",
    "        'year' in line and \\\n",
    "        'fos' in line and \\\n",
    "        'venue' in line and 'raw' in line['venue'] and \\\n",
    "        'authors' in line:\n",
    "        \n",
    "            if line['venue']['raw'] not in venue_id: \n",
    "                venue_id[line['venue']['raw']] = f'V{next_venue_id}'\n",
    "                next_venue_id += 1\n",
    "            \n",
    "            data['id'] = 'C'+line['id']\n",
    "            data['title'] = line['title']\n",
    "            data['year'] = int(line['year'])\n",
    "            data['venue'] = venue_id[line['venue']['raw']]            \n",
    "            data['fos'] = [(fos.get('name'), float(fos.get('w'))) for fos in line['fos']]\n",
    "            data['authors'] = [('A'+author.get('id'), author.get('name'), author.get('org')) for author in line['authors']]\n",
    "            data['outcitations'] = ['C'+reference for reference in line['references']] if 'references' in line else []\n",
    "            \n",
    "            return data, next_venue_id\n",
    "    \n",
    "    return None, next_venue_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_years(years):\n",
    "    \n",
    "    contents = defaultdict(dict)\n",
    "    next_venue_id = 0\n",
    "    \n",
    "    with open('raw/dblp_papers_v11.txt','r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            \n",
    "            line = json.loads(line)\n",
    "            if 'year' in line and years[0] <= int(line.get('year')) < years[1]:\n",
    "                data, next_venue_id = validate(line, next_venue_id)\n",
    "                \n",
    "                if data != None:\n",
    "                    contents[data['year']][data['id']] = Content(data)\n",
    "                    content_year[data['id']] = data['year']\n",
    "                    content_pool.add(data['id'])                 \n",
    "                                    \n",
    "            if i%100000 == 0:\n",
    "                print('Extraction done for line {}'.format(i))\n",
    "                \n",
    "        print('Total: {}, Remaining: {}'.format(i+1, sum([len(contents[year]) for year in range(years[0],years[1])])))\n",
    "            \n",
    "    for year in range(years[0],years[1]):\n",
    "        pickle.dump(contents[year], open('content/contents_{}.pkl'.format(year), 'wb'), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year, end_year = 1980, 2019\n",
    "\n",
    "content_pool = set()\n",
    "content_year = {}\n",
    "venue_id = {}\n",
    "\n",
    "extract_years((start_year,end_year))\n",
    "\n",
    "pickle.dump(content_pool, open('content/content_pool.pkl', 'wb'), -1)\n",
    "pickle.dump(content_year, open('content/content_year.pkl', 'wb'), -1)\n",
    "pickle.dump(venue_id, open('venue/venue_id.pkl', 'wb'), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Out/In-citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_year, end_year = 1980, 2019\n",
    "content_year = pickle.load(open('content/content_year.pkl','rb'))\n",
    "content_pool = pickle.load(open('content/content_pool.pkl','rb'))\n",
    "incitations_dict = defaultdict(list)\n",
    "\n",
    "for year in range(start_year, end_year):    \n",
    "    contents = pickle.load(open('content/contents_{}.pkl'.format(year),'rb'))    \n",
    "    for out_content in contents.values():        \n",
    "        outcitations = []\n",
    "        for in_content in out_content.outcitations:\n",
    "            if in_content in content_pool and content_year[in_content]<out_content.year:\n",
    "                    incitations_dict[in_content].append((out_content.id, out_content.year))\n",
    "                    outcitations.append(in_content)\n",
    "        out_content.outcitations = outcitations\n",
    "    pickle.dump(contents, open('content/contents_{}.pkl'.format(year), 'wb'), -1)\n",
    "    print('Out citation done for year {}'.format(year))\n",
    "                \n",
    "for year in range(start_year, end_year):    \n",
    "    contents = pickle.load(open('content/contents_{}.pkl'.format(year),'rb'))    \n",
    "    for out_content in contents.values():\n",
    "        out_content.update_incitations(incitations_dict[out_content.id])    \n",
    "    pickle.dump(contents, open('content/contents_{}.pkl'.format(year), 'wb'), -1)\n",
    "    print('In citation done for year {}'.format(year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year, end_year = 1980, 2019\n",
    "\n",
    "field_pool = set()\n",
    "venue_pool = set()\n",
    "content_pool = set()\n",
    "content_year = {}\n",
    "content_authors = {}\n",
    "\n",
    "paper_count = 0 # 3974198 \n",
    "for year in range(start_year, end_year):    \n",
    "    contents = pickle.load(open('content/contents_{}.pkl'.format(year),'rb'))\n",
    "    paper_count += len(contents)\n",
    "    for content in contents.values():        \n",
    "        for field in content.fos:\n",
    "            field_pool.add(field[0])               \n",
    "        venue_pool.add(content.venue)\n",
    "        content_pool.add(content.id)\n",
    "        content_year[content.id] = year\n",
    "        content_authors[content.id] = [author[0] for author in content.authors]\n",
    "    print(f'Collection done for year {year}')\n",
    "        \n",
    "pickle.dump(field_pool, open('content/field_pool.pkl', 'wb'), -1)\n",
    "pickle.dump(venue_pool, open('venue/venue_pool.pkl', 'wb'), -1)\n",
    "pickle.dump(content_pool, open('content/content_pool.pkl', 'wb'), -1)\n",
    "pickle.dump(content_year, open('content/content_year.pkl', 'wb'), -1)\n",
    "pickle.dump(content_authors, open('content/content_authors.pkl', 'wb'), -1)\n",
    "\n",
    "field_dict = dict((field,index) for index,field in enumerate(field_pool))\n",
    "field_count = len(field_pool) # 106650\n",
    "\n",
    "print(paper_count, field_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "field_weights = lil_matrix((paper_count, field_count), dtype=np.float32)\n",
    "for year in range(start_year, end_year):    \n",
    "    contents = pickle.load(open('content/contents_{}.pkl'.format(year),'rb'))\n",
    "    for out_content in contents.values():        \n",
    "        for field, weight in out_content.fos:\n",
    "            field_weights[index, field_dict[field]] = weight\n",
    "        index += 1\n",
    "    print('Field done for year {}'.format(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_reduced = TruncatedSVD(n_components=100).fit_transform(field_weights.tocsr())\n",
    "pickle.dump(field_reduced, open('content/field_reduced.pkl', 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('LSA done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year, end_year = 1980, 2019\n",
    "field_reduced = pickle.load(open('content/field_reduced.pkl','rb'))\n",
    "\n",
    "index = 0\n",
    "for year in range(start_year, end_year):    \n",
    "    contents = pickle.load(open('content/contents_{}.pkl'.format(year),'rb'))\n",
    "    print(year, len(contents))\n",
    "    for out_content in contents.values():\n",
    "        out_content.update_field(field_reduced[index])\n",
    "        index += 1\n",
    "    pickle.dump(contents, open('content/contents_{}.pkl'.format(year), 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('Total number of contents:', index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C-C & C-A & C-U Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_adjs = {}\n",
    "ca_adjs = {}\n",
    "cu_adjs = {}\n",
    "content_year = pickle.load(open('content/content_year.pkl','rb'))\n",
    "\n",
    "for year in range(1980, 2019):\n",
    "    contents =  pickle.load(open('content/contents_{}.pkl'.format(year),'rb'))\n",
    "    for content in contents.values():\n",
    "        cc_adjs[content.id+str(year)] = [outid+str(content_year[outid]) for outid in content.outcitations]\n",
    "        ca_adjs[content.id+str(year)] = [author_id+str(year) for author_id,_,_ in content.authors]\n",
    "        cu_adjs[content.id+str(year)] = [content.venue+str(year)]\n",
    "    print('done for year {}'.format(year))\n",
    "\n",
    "pickle.dump(cc_adjs, open('content/cc_adjs.pkl', 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(ca_adjs, open('content/ca_adjs.pkl', 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(cu_adjs, open('content/cu_adjs.pkl', 'wb'), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_embs = pickle.load(open('content/c_embs.pkl','rb'))\n",
    "\n",
    "update_counts = 0\n",
    "for year in range(1980, 2019):\n",
    "    \n",
    "    print('Reading year {}'.format(year))\n",
    "    contents =  pickle.load(open('content/contents_{}.pkl'.format(year),'rb'))\n",
    "    \n",
    "    print('Embedding-update start for year {}'.format(year))\n",
    "    for content in contents.values():        \n",
    "        content.update_embedding(c_embs[content.id+str(year)])\n",
    "        update_counts += 1\n",
    "            \n",
    "    print('Writing year {}'.format(year))\n",
    "    pickle.dump(contents, open('content/contents_{}.pkl'.format(year), 'wb'), -1)\n",
    "    del contents\n",
    "    \n",
    "    print('Embedding-update done for year {}'.format(year))\n",
    "    print()\n",
    "    \n",
    "print('Count check: {} vs {}'.format(len(c_embs), update_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content_year = pickle.load(open('content/content_year.pkl','rb'))\n",
    "content_authors = pickle.load(open('content/content_authors.pkl', 'rb'))\n",
    "\n",
    "authoryear_pool, venueyear_pool = set(), set()\n",
    "content_inauthoryears, content_venueyears = defaultdict(list), {}\n",
    "\n",
    "for year in range(1980, 2019):\n",
    "    \n",
    "    print('Reading year {}'.format(year))\n",
    "    contents =  pickle.load(open('content/contents_{}.pkl'.format(year),'rb'))\n",
    "    \n",
    "    print('Collection start for year {}'.format(year))\n",
    "    for content in contents.values():        \n",
    "        \n",
    "        for author,_,_ in content.authors:\n",
    "            authoryear_pool.add(author+str(year))\n",
    "        venueyear_pool.add(content.venue+str(year))\n",
    "        \n",
    "        for incontent in content.outcitations:\n",
    "            for inauthor in content_authors[incontent]:\n",
    "                content_inauthoryears[content.id].append(inauthor+str(content_year[incontent]))\n",
    "        content_venueyears[content.id] = content.venue+str(year)\n",
    "    \n",
    "    print('Collection done for year {}'.format(year))\n",
    "    print()\n",
    "\n",
    "pickle.dump(authoryear_pool, open('author/authoryear_pool.pkl','wb'),-1)\n",
    "pickle.dump(venueyear_pool, open('venue/venueyear_pool.pkl','wb'),-1)\n",
    "pickle.dump(content_inauthoryears, open('content/content_inauthoryears.pkl','wb'),-1)\n",
    "pickle.dump(content_venueyears, open('content/content_venueyears.pkl','wb'),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content_incontents = {}\n",
    "\n",
    "for year in range(1980, 2019):\n",
    "    \n",
    "    print('Reading year {}'.format(year))\n",
    "    contents =  pickle.load(open('content/contents_{}.pkl'.format(year),'rb'))\n",
    "    \n",
    "    print('Collection start for year {}'.format(year))\n",
    "    for content in contents.values():        \n",
    "        \n",
    "        if len(content.outcitations)>0:\n",
    "            content_incontents[content.id] = content.outcitations\n",
    "    \n",
    "    print('Collection done for year {}'.format(year))\n",
    "    print()\n",
    "\n",
    "pickle.dump(content_incontents, open('content/content_incontents.pkl','wb'),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
